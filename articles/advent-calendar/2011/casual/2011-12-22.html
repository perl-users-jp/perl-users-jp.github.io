<!doctype html>
<html lang="ja">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <meta name="description" content="">
        <meta name="author" content="akiym">
        <title>Webスクレイピング入門 - Articles Advent Calendar 2011 Casual</title>
        <link rel="icon" href="/img/favicon.ico">
        <link href="TODO" rel="stylesheet">
    </head>
    <body>
        <h1>Webスクレイピング入門</h1>

        <p>みなさんこんにちは。<a href="http://twitter.com/#!/akiym">akiym</a>です。<br />
今日はWebスクレイピングの話をします。</p>

<div class="section">
    <h4>Webスクレイピングとは？</h4>
    <p>例えば、<a href="http://blog.livedoor.jp/chihhylove/archives/3573873.html">&#x6607;&#x5929;&#x3059;&#x308B;&#x304F;&#x3089;&#x3044;&#x304B;&#x308F;&#x3044;&#x3044;&#x732B;&#x753B;&#x50CF;&#x304F;&#x3060;&#x3055;&#x3044; : &#x3042;&#x3058;&#x3083;&#x3058;&#x3083;&#x3057;&#x305F;&#x30FC;</a>の猫の画像が欲しいときにどうすればいいでしょうか<a href="#fn1" title="とくに深い意味はありません。">*1</a>。画像を1つずつ手作業で保存？面倒くさいですね。<br />
そんなときのためのWebスクレイピングです。まずはじめは、<a href="https://metacpan.org/module/Web::Scraper">Web::Scraper</a>というモジュールを使ってみましょう。</p>

    <pre class="code lang-perl">use strict;
use warnings;
use autodie;
use File::Basename;
use File::Spec;
use LWP::UserAgent;
use URI;
use Web::Scraper;

my $url = &#39;http://blog.livedoor.jp/chihhylove/archives/3573873.html&#39;;
my $scraper = scraper {
    process &#39;.main img.pict, .mainmore img.pict&#39;, &#39;images[]&#39; =&gt; &#39;@src&#39;;
};
my $res = $scraper-&gt;scrape(URI-&gt;new($url));

my $dir = &#39;cats&#39;;
mkdir $dir unless -d $dir;

my $ua = LWP::UserAgent-&gt;new;
for my $image_url (@{$res-&gt;{images}}) {
    my $filename = File::Spec-&gt;catfile($dir, basename($image_url));
    print &#34;Downloading: $image_url\n&#34;;
    my $res = $ua-&gt;get($image_url, &#39;:content_file&#39; =&gt; $filename);
    die unless $res-&gt;is_success;
}</pre>
<p>基本的にはこのような感じです。Web::Scraperで猫の画像のURLを取得してきて、LWP::UserAgentで画像を保存しています。<br />
応用すれば、猫の画像以外でも簡単にダウンロードができます。悪用厳禁ですね :)</p>

</div>
<div class="section">
    <h4>もっと簡単に</h4>
    <p>上の例では、Web::Scraperを使ってみましたが使い方が少し複雑で難しいですね。もっと簡単に扱えるモジュールはないのでしょうか？<br />
そんなときには、<a href="https://metacpan.org/module/Web::Query">Web::Query</a>がおすすめです。jQuery風にWebスクレイピングできるとても便利なモジュールです。<br />
先ほどの例をWeb::Queryを使って書きなおしてみましょう。</p>

    <pre class="code lang-perl">use strict;
use warnings;
use autodie;
use File::Basename;
use File::Spec;
use LWP::UserAgent;
use Web::Query;

my $dir = &#39;cats&#39;;
mkdir $dir unless -d $dir;

my $ua = LWP::UserAgent-&gt;new;

my $url = &#39;http://blog.livedoor.jp/chihhylove/archives/3573873.html&#39;;
wq($url)
    -&gt;find(&#39;.main img.pict, .mainmore img.pict&#39;)
    -&gt;each(sub {
        my $image_url = $_-&gt;attr(&#39;src&#39;);
        my $filename = File::Spec-&gt;catfile($dir, basename($image_url));
        print &#34;Downloading: $image_url\n&#34;;
        my $res = $ua-&gt;get($image_url, &#39;:content_file&#39; =&gt; $filename);
        die $res-&gt;status_line unless $res-&gt;is_success;
    });</pre>
<p>やっていることは変わりませんが、とてもシンプルなコードになりました！</p>

</div>
<div class="section">
    <h4>例2</h4>
    <p><a href="http://d.hatena.ne.jp/gfx/20111221/1324466676">&#x53E4;&#x3044;Perl Advent Calendar&#x3082;&#x6848;&#x5916;&#x9762;&#x767D;&#x304B;&#x3063;&#x305F;&#x308A;&#x3059;&#x308B;&#x306E;&#x3067; - Islands in the byte stream</a>より</p>

<blockquote >
    <p>しかし2009年以前はブクマ数が一覧から見えないのでどれが人気だったのかわかりませんね。</p>

    
</blockquote><p>ここで、Webスクレピングを使ってみます。ページの一覧を取ってきて、そこからブックマーク数を取得してみましょう。ブックマーク数を取得するには<a href="http://developer.hatena.ne.jp/ja/documents/bookmark/apis/getcount">&#x306F;&#x3066;&#x306A;&#x30D6;&#x30C3;&#x30AF;&#x30DE;&#x30FC;&#x30AF;&#x4EF6;&#x6570;&#x53D6;&#x5F97;API</a>を使います。</p>

    <pre class="code lang-perl">use strict;
use warnings;
use Encode;
use LWP::UserAgent;
use URI::Escape;
use Web::Query;

my $ua = LWP::UserAgent-&gt;new;

my $url = &#39;/articles/advent-calendar/2009/&#39;;
my @tracks = wq($url)-&gt;find(&#39;#alpha-inner h3 a&#39;)-&gt;attr(&#39;href&#39;);
for my $track (@tracks) {
    $track =~ s!^\./!!;
    $track = $url . $track;
    print &#34;=&gt; $track\n&#34;;
    wq($track)-&gt;find(&#39;#alpha-inner ul li a&#39;)-&gt;each(sub {
        my $title = decode_utf8($_-&gt;text);
        my $escaped_url = uri_escape($track . $_-&gt;attr(&#39;href&#39;));
        # APIを使ってブックマーク数を取得する
        my $res = $ua-&gt;get(&#34;http://api.b.st-hatena.com/entry.count?url=$escaped_url&#34;);
        die $res-&gt;status_line unless $res-&gt;is_success;
        my $count = $res-&gt;content || 0;
        printf &#34;%s: %d\n&#34;, encode_utf8($title), $count;
    });
}</pre>

</div>
<div class="section">
    <h4>まとめ</h4>
    <p>Web::QueryでラクラクWebスクレイピング！<br />
Web::Scraperというモジュールも紹介しましたが、個人的にはWeb::Queryのほうがカジュアルでかっこいいんじゃないかな、と思います。<br />
みなさんもじゃんじゃんWebスクレピングしまくってみてください！ただし悪用厳禁で :)<br />
次はotsuneさんです。</p>

</div>HASH(0x5577e0bb3e20)
        <script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js?lang=css&amp;skin=sunburst"></script>
    </body>
</html>
